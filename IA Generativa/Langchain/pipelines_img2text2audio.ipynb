{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce2091b3-ec40-4d20-b6c2-e466008baa67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openai\n",
      "  Using cached langchain_openai-0.0.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from langchain_openai) (0.1.17)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from langchain_openai) (1.26.3)\n",
      "Collecting openai<2.0.0,>=1.10.0 (from langchain_openai)\n",
      "  Using cached openai-1.10.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tiktoken<0.6.0,>=0.5.2 (from langchain_openai)\n",
      "  Downloading tiktoken-0.5.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.16->langchain_openai) (6.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.16->langchain_openai) (4.2.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.16->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.16->langchain_openai) (0.0.85)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.16->langchain_openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.16->langchain_openai) (2.6.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.16->langchain_openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.16->langchain_openai) (8.2.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.26.0)\n",
      "Requirement already satisfied: sniffio in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from tiktoken<0.6.0,>=0.5.2->langchain_openai) (2023.10.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain_openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain_openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.16->langchain_openai) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.16->langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.16->langchain_openai) (2.16.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain_openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain_openai) (2.1.0)\n",
      "Using cached langchain_openai-0.0.5-py3-none-any.whl (29 kB)\n",
      "Using cached openai-1.10.0-py3-none-any.whl (225 kB)\n",
      "Downloading tiktoken-0.5.2-cp310-cp310-macosx_11_0_arm64.whl (953 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken, openai, langchain_openai\n",
      "Successfully installed langchain_openai-0.0.5 openai-1.10.0 tiktoken-0.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd8de162-09b8-4907-be84-b84d14f52754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from datasets) (1.26.3)\n",
      "Collecting pyarrow>=8.0.0 (from datasets)\n",
      "  Downloading pyarrow-15.0.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from datasets) (0.20.2)\n",
      "Requirement already satisfied: packaging in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-15.0.0-cp310-cp310-macosx_11_0_arm64.whl (24.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow, datasets\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 5.0.0\n",
      "    Uninstalling pyarrow-5.0.0:\n",
      "      Successfully uninstalled pyarrow-5.0.0\n",
      "Successfully installed datasets-2.16.1 pyarrow-15.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea63ea30-9026-46e1-b5a5-d04945bdb94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eac6bf70-ba7c-481a-80f3-8ba6325d525f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/n.c.rodriguez/anaconda3/envs/nico/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import scipy\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain_openai import OpenAI\n",
    "import torch\n",
    "from IPython.display import Image\n",
    "from datasets import load_dataset\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9b2b825-c025-44f6-b19d-354194ac7654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "# Configurar el motor de OpenAI\n",
    "engine = \"gpt-3.5-turbo\"\n",
    "api_key=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab4dc728-62d6-47e0-9bf7-83da119afc31",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "OpenAI.__init__() got an unexpected keyword argument 'openai_api_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopenai_api_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: OpenAI.__init__() got an unexpected keyword argument 'openai_api_key'"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(openai_api_key=api_key, temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca9407cc-00e8-466e-9645-a7cc24a4d3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0cfc52c20944ed9cf30952346601ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51556386ca64f8fb6918c9ca5f78b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7406f21af74885b24ae1028c743cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c548cd57f4434da504d1bf2b07cf32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93e7af5b1e74e8a94e93888e3bb0c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1534975b8d34ecdb6546baaead8fc47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "captioner = pipeline(\"image-to-text\",model=\"Salesforce/blip-image-captioning-base\", max_new_tokens=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bfb612d-4c14-4b68-acac-6b7857611c30",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for LLMChain\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 31\u001b[0m\n\u001b[1;32m     26\u001b[0m   scipy\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mwavfile\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistoria.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, rate\u001b[38;5;241m=\u001b[39mspeech[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampling_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m], data\u001b[38;5;241m=\u001b[39mspeech[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     29\u001b[0m generated_topic \u001b[38;5;241m=\u001b[39m image2text(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/datasets/Narsil/image_dummy/resolve/main/parrots.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m historia \u001b[38;5;241m=\u001b[39m \u001b[43mcrear_historia\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_topic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m crear_audio(historia)\n",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m, in \u001b[0;36mcrear_historia\u001b[0;34m(topic)\u001b[0m\n\u001b[1;32m      6\u001b[0m template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124mYou are a writer and story teller.\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124mYour task is generate short stories from a shrot description. The story cannot have more than 50 words.\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124mCONTEXT: \u001b[39m\u001b[38;5;132;01m{topic}\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124mSTORY:\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     12\u001b[0m topic_template \u001b[38;5;241m=\u001b[39m PromptTemplate(template\u001b[38;5;241m=\u001b[39mtemplate, input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 14\u001b[0m topic_chain \u001b[38;5;241m=\u001b[39m \u001b[43mLLMChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtopic_template\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m response \u001b[38;5;241m=\u001b[39m topic_chain\u001b[38;5;241m.\u001b[39minvoke(topic)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/nico/lib/python3.10/site-packages/langchain_core/load/serializable.py:107\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/anaconda3/envs/nico/lib/python3.10/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for LLMChain\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)"
     ]
    }
   ],
   "source": [
    "def image2text(image):\n",
    "    text_result = captioner(image)\n",
    "    return text_result[0]['generated_text']\n",
    "\n",
    "def crear_historia(topic):\n",
    "   template = \"\"\"\n",
    "   You are a writer and story teller.\n",
    "   Your task is generate short stories from a shrot description. The story cannot have more than 50 words.\n",
    "   CONTEXT: {topic}\n",
    "   STORY:\n",
    "   \"\"\"\n",
    "   topic_template = PromptTemplate(template=template, input_variables=['topic'])\n",
    "\n",
    "   topic_chain = LLMChain(llm=llm, prompt=topic_template)\n",
    "   response = topic_chain.invoke(topic)\n",
    "   print(response.get('text'))\n",
    "   return response.get('text')\n",
    "\n",
    "def crear_audio(text):\n",
    "  synthesiser = pipeline(\"text-to-speech\", model=\"microsoft/speecht5_tts\")\n",
    "  embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "  speaker_embedding = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n",
    "\n",
    "  speech = synthesiser(f\"{text}\", forward_params={\"speaker_embeddings\": speaker_embedding})\n",
    "\n",
    "  scipy.io.wavfile.write(\"historia.wav\", rate=speech[\"sampling_rate\"], data=speech[\"audio\"])\n",
    "\n",
    "\n",
    "generated_topic = image2text(\"https://huggingface.co/datasets/Narsil/image_dummy/resolve/main/parrots.png\")\n",
    "\n",
    "historia = crear_historia(generated_topic)\n",
    "crear_audio(historia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998ad1ca-758b-4918-a641-728aacf4bce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
