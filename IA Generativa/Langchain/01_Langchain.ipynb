{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1114ec",
   "metadata": {
    "id": "ff1114ec"
   },
   "outputs": [],
   "source": [
    "# Si no tenemos el módulo instalado\n",
    "#!pip install langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c26cd69",
   "metadata": {
    "id": "7c26cd69"
   },
   "source": [
    "### LangChain: Modelos, Prompts and Parsers de salida\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40d20e42",
   "metadata": {
    "id": "40d20e42"
   },
   "outputs": [],
   "source": [
    "# Primero importamos las bibliotecas necesarias:\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8079c1e3-694c-42b4-9879-59d47617449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "# Configurar el motor de OpenAI\n",
    "engine = \"gpt-3.5-turbo\"\n",
    "api_key=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74819297",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "id": "74819297",
    "outputId": "216c1aa5-d4bb-469f-b18f-8810332ce3ce"
   },
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0.7, model=engine,openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44627a5",
   "metadata": {
    "id": "f44627a5"
   },
   "source": [
    "## Plantilla de Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2d4e320",
   "metadata": {
    "id": "f2d4e320"
   },
   "outputs": [],
   "source": [
    "estilo_formal = \"\"\"Español Castellano \\\n",
    "correcto, educado y conciliador\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56854229",
   "metadata": {
    "id": "56854229"
   },
   "outputs": [],
   "source": [
    "plantilla = \"\"\"Transforma el texto \\\n",
    "delimitado por acento grave triple \\\n",
    "en un texto con el estilo {estilo}. \\\n",
    "text: ```{texto}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2449a03a",
   "metadata": {
    "id": "2449a03a"
   },
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(plantilla)\n",
    "#prompt_template.messages[0].prompt\n",
    "#prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55a05428",
   "metadata": {
    "id": "55a05428"
   },
   "outputs": [],
   "source": [
    "texto_original = \"\"\"\n",
    "Bueno, la verdad es que paso bastante de los resultados.\n",
    "Me importa un bledo lo que piensen en dirección. La próxima ver que me contacten\n",
    "para hablar de esto, les voy a mandar al carajo!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07f43898",
   "metadata": {
    "id": "07f43898"
   },
   "outputs": [],
   "source": [
    "messages = prompt_template.format_messages(\n",
    "                    estilo=estilo_formal,\n",
    "                    texto=texto_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa7e2c32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa7e2c32",
    "outputId": "9eeeac83-828a-4900-b137-903e6036340a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n",
      "content='Transforma el texto delimitado por acento grave triple en un texto con el estilo Español Castellano correcto, educado y conciliador\\n. text: ```\\nBueno, la verdad es que paso bastante de los resultados.\\nMe importa un bledo lo que piensen en dirección. La próxima ver que me contacten\\npara hablar de esto, les voy a mandar al carajo!\\n```\\n'\n"
     ]
    }
   ],
   "source": [
    "print(type(messages))\n",
    "print(type(messages[0]))\n",
    "print(messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ddbba0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ddbba0d",
    "outputId": "46a007ad-242c-458b-f2f1-3442ffedd44d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Bueno, la verdad es que no le doy mucha importancia a los resultados. No me preocupa en absoluto lo que piensen en dirección. La próxima vez que me contacten para tratar este asunto, les manifestaré mi desacuerdo de una manera más educada.'\n"
     ]
    }
   ],
   "source": [
    "###Llamamos al LLM para transformar el mensaje según la plantilla\n",
    "\n",
    "response = chat.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c8c5f0",
   "metadata": {
    "id": "a4c8c5f0"
   },
   "source": [
    "### Procesador de salida (output parsers)\n",
    "Ayudan a transformar la salida cruda del modelo en algo más utilizable o en un formato específico que sea más fácil de manejar en la aplicación donde se utiliza el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "851f3df6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "851f3df6",
    "outputId": "aa4966ac-d6aa-4bac-8e35-32c8a73ec77b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'difícil': False,\n",
       " 'profesor': 'Muy bueno!',\n",
       " 'calidad_precio': 'buena relación calidad-precio'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"difícil\": False,\n",
    "  \"profesor\": \"Muy bueno!\",\n",
    "  \"calidad_precio\": \"buena relación calidad-precio\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "538ea5cf",
   "metadata": {
    "id": "538ea5cf"
   },
   "outputs": [],
   "source": [
    "valoracion = \"\"\"\\\n",
    "Me ha gustado mucho el curso. El profesor ha sido muy profesional\n",
    "y se notaba su experiencia y grandes conocimientos.\n",
    "A pesar de ello, era la primera vez que estudiaba estos conceptos\n",
    "y me costó un poco asimilarlos.\n",
    "Estoy muy contento con haber hecho esta inversión de dinero en mi conocimiento.\n",
    "Lo recomendaré a otros colegas de trabajo!\n",
    "\"\"\"\n",
    "\n",
    "plantilla = \"\"\"\\\n",
    "Del siguiente texto, extrae la siguiente información:\n",
    "\n",
    "dificultad: El curso le resulto fácil o difícil\n",
    "Contesta True si fue difícil, False si no lo fue o no se indica.\n",
    "\n",
    "profesor: El profesor cumplió con sus expectativas?\n",
    "Valoralo el sentimiento sobre el profesor del 1 al 5.\n",
    "Si no se menciona nada sobre el profesor devuelve -1.\n",
    "\n",
    "calidad_precio: Extrae cualquier referencia a la calidad o precio,\\\n",
    "y relacionalos ofreciendo el sentimiento.\n",
    "\n",
    "Formatea la salida como JSON con las siguientes claves:\n",
    "dificultad\n",
    "profesor\n",
    "calidad_precio\n",
    "\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef884bd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ef884bd4",
    "outputId": "880920ad-2613-4c33-9ebe-eff24ad8a418"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='Del siguiente texto, extrae la siguiente información:\\n\\ndificultad: El curso le resulto fácil o difícil\\nContesta True si fue difícil, False si no lo fue o no se indica.\\n\\nprofesor: El profesor cumplió con sus expectativas?\\nValoralo el sentimiento sobre el profesor del 1 al 5.\\nSi no se menciona nada sobre el profesor devuelve -1.\\n\\ncalidad_precio: Extrae cualquier referencia a la calidad o precio,y relacionalos ofreciendo el sentimiento.\\n\\nFormatea la salida como JSON con las siguientes claves:\\ndificultad\\nprofesor\\ncalidad_precio\\n\\ntext: {text}\\n'))]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_plantilla = ChatPromptTemplate.from_template(plantilla)\n",
    "print(prompt_plantilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7da2a03c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7da2a03c",
    "outputId": "c2f92c02-97f0-49f3-d5b0-6b6f4a5becea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"dificultad\": true,\n",
      "  \"profesor\": 5,\n",
      "  \"calidad_precio\": \"inversión de dinero\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = prompt_plantilla.format_messages(text=valoracion)\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.7, openai_api_key=api_key)\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efc38b86",
   "metadata": {
    "id": "efc38b86"
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66c4d3b9",
   "metadata": {
    "id": "66c4d3b9"
   },
   "outputs": [],
   "source": [
    "dificultad_schema = ResponseSchema(name=\"dificultad\", description=\"¿El curso le resulto fácil o difícil? Contesta True si fue difícil, False si no lo fue o no se indica.\")\n",
    "profesor_schema = ResponseSchema(name=\"profesor\", description=\"El profesor cumplió con sus expectativas? Valoralo el sentimiento sobre el profesor del 1 al 5. Si no se menciona nada sobre el profesor devuelve -1.\")\n",
    "calidad_precio_schema = ResponseSchema(name=\"calidad_precio\", description=\"Extrae cualquier referencia a la calidad o el precio y relaciónalos ofreciendo el sentimiento.\")\n",
    "\n",
    "response_schemas = [dificultad_schema,\n",
    "                    profesor_schema,\n",
    "                    calidad_precio_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9f8be9b",
   "metadata": {
    "id": "d9f8be9b"
   },
   "outputs": [],
   "source": [
    "procesador_salida = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a755baa7",
   "metadata": {
    "id": "a755baa7"
   },
   "outputs": [],
   "source": [
    "format_instructions = procesador_salida.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1432afc8",
   "metadata": {
    "id": "1432afc8"
   },
   "outputs": [],
   "source": [
    "plantilla2 = \"\"\"\\\n",
    "Del siguiente texto, extrae la siguiente información:\n",
    "\n",
    "dificultad: El curso le resulto fácil o difícil. Contesta True si fue difícil, False si no lo fue o no se indica.\n",
    "\n",
    "profesor: El profesor cumplió con sus expectativas? Valoralo el sentimiento sobre el profesor del 1 al 5. Si no se menciona nada sobre el profesor devuelve -1.\n",
    "\n",
    "calidad_precio: Extrae cualquier referencia a la calidad o precio y relacionalos ofreciendo el sentimiento.\n",
    "\n",
    "Formatea la salida como JSON con las siguientes claves:\n",
    "dificultad\n",
    "profesor\n",
    "calidad_precio\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=plantilla2)\n",
    "\n",
    "messages = prompt.format_messages(text=valoracion, format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0676a3ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0676a3ca",
    "outputId": "2b7ad1cc-fd9e-4056-d4eb-fe678ca6f0be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Del siguiente texto, extrae la siguiente información:\n",
      "\n",
      "dificultad: El curso le resulto fácil o difícil. Contesta True si fue difícil, False si no lo fue o no se indica.\n",
      "\n",
      "profesor: El profesor cumplió con sus expectativas? Valoralo el sentimiento sobre el profesor del 1 al 5. Si no se menciona nada sobre el profesor devuelve -1.\n",
      "\n",
      "calidad_precio: Extrae cualquier referencia a la calidad o precio y relacionalos ofreciendo el sentimiento.\n",
      "\n",
      "Formatea la salida como JSON con las siguientes claves:\n",
      "dificultad\n",
      "profesor\n",
      "calidad_precio\n",
      "\n",
      "text: Me ha gustado mucho el curso. El profesor ha sido muy profesional\n",
      "y se notaba su experiencia y grandes conocimientos.\n",
      "A pesar de ello, era la primera vez que estudiaba estos conceptos\n",
      "y me costó un poco asimilarlos.\n",
      "Estoy muy contento con haber hecho esta inversión de dinero en mi conocimiento.\n",
      "Lo recomendaré a otros colegas de trabajo!\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"dificultad\": string  // ¿El curso le resulto fácil o difícil? Contesta True si fue difícil, False si no lo fue o no se indica.\n",
      "\t\"profesor\": string  // El profesor cumplió con sus expectativas? Valoralo el sentimiento sobre el profesor del 1 al 5. Si no se menciona nada sobre el profesor devuelve -1.\n",
      "\t\"calidad_precio\": string  // Extrae cualquier referencia a la calidad o el precio y relaciónalos ofreciendo el sentimiento.\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e1815cd",
   "metadata": {
    "id": "6e1815cd"
   },
   "outputs": [],
   "source": [
    "response = chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58e318a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58e318a7",
    "outputId": "d35087b4-b931-450d-eb1d-5e0eea703c6f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"dificultad\": true,\n",
      "\t\"profesor\": 5,\n",
      "\t\"calidad_precio\": \"positivo\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b055ae3",
   "metadata": {
    "id": "6b055ae3"
   },
   "outputs": [],
   "source": [
    "output_dict = procesador_salida.parse(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a19e8f6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a19e8f6a",
    "outputId": "71845b27-dcd4-4cb7-c11d-38981189e1de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dificultad': True, 'profesor': 5, 'calidad_precio': 'positivo'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
