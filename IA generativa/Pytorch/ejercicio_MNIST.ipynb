{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff95664f-e220-4f9a-b115-f3604607ee79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /Users/n.c.rodriguez/anaconda3/lib/python3.11/site-packages (2.1.2)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/torchvision-0.2.0-py2.py3-none-any.whl (48 kB)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torchaudio (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torchaudio\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe63ad81-910a-4414-8a2e-8fee28543f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/ef/a2/f16cac894c4c71585b3411707502ed8d607945fb4a695857621565bd728d/torchvision-0.16.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading torchvision-0.16.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in /Users/n.c.rodriguez/anaconda3/lib/python3.11/site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: requests in /Users/n.c.rodriguez/anaconda3/lib/python3.11/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.2 in /Users/n.c.rodriguez/anaconda3/lib/python3.11/site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/n.c.rodriguez/anaconda3/lib/python3.11/site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: filelock in /Users/n.c.rodriguez/anaconda3/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/n.c.rodriguez/anaconda3/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/n.c.rodriguez/anaconda3/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/n.c.rodriguez/anaconda3/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/n.c.rodriguez/anaconda3/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/n.c.rodriguez/anaconda3/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (2023.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/n.c.rodriguez/anaconda3/lib/python3.11/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/n.c.rodriguez/anaconda3/lib/python3.11/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/n.c.rodriguez/anaconda3/lib/python3.11/site-packages (from requests->torchvision) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/n.c.rodriguez/anaconda3/lib/python3.11/site-packages (from requests->torchvision) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/n.c.rodriguez/anaconda3/lib/python3.11/site-packages (from jinja2->torch==2.1.2->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/n.c.rodriguez/anaconda3/lib/python3.11/site-packages (from sympy->torch==2.1.2->torchvision) (1.3.0)\n",
      "Downloading torchvision-0.16.2-cp311-cp311-macosx_11_0_arm64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchvision\n",
      "Successfully installed torchvision-0.16.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f497a50-9dd3-4b96-8182-75a9a4279018",
   "metadata": {},
   "source": [
    "## Importación librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b81386d9-1b3c-429b-915c-4a5063c6778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de las bibliotecas de PyTorch\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms \n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44af314-f443-4542-93a5-e81e604d11e4",
   "metadata": {},
   "source": [
    "## Creación y entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff50feb-b1e3-495a-8165-21b0c6bbbbf7",
   "metadata": {},
   "source": [
    "Primero se crea una clase para crear una red neuronal de dos capa totalmente conectada, tomando imágenes planas de 28x28 como entrada y proporcionando una salida que se pueda usar para clasificar esas imágenes en 10 categorías (de 0 a 9, siendo estos los números que se quieren predecir).\n",
    "\n",
    "Es un ejemplo típico de una red neuronal básica utilizada para tareas de clasificación de dígitos en el conjunto de datos MNIST.\n",
    "\n",
    "Para simplificar en el diagrama de red neuronal, la capa oculta sería fc1 y la capa de salida sería fc2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af22c449-d56e-429c-957b-095f3053578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una clase llamada SimpleNet que va a heredar de pytorch.nn.Module\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 64) #28*28 es la dimensión de la imagen\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28) #para aplanar la imagen\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345d1393-fd5e-4de1-9791-99e267069323",
   "metadata": {},
   "source": [
    "A continuación se define una función de entrenamiento. \n",
    "La primera línea transforms.Compose es un método que encadena varias transformaciones de imágenes. Aquí, está combinando dos transformaciones:\n",
    "- *transforms.ToTensor()* convierte imágenes PIL o ndarray de NumPy en tensores de PyTorch.\n",
    "- *transforms.Normalize((0.5,), (0.5,))* normaliza las imágenes tensoras con media y desviación estándar, que son 0.5 para cada canal. Esto se hace porque el conjunto de datos MNIST es en escala de grises, por lo tanto, tiene un solo canal\n",
    "\n",
    "En la segunda línea se carga el conjunto de datos de MNIST:\n",
    "- *root=* especifica el directorio donde se almacenará o se almacena el conjunto de datos\n",
    "- *train=True* indica que se debe descargar el conjunto de entrenamiento\n",
    "- *download=True* le dice a la función que descargue los datos si aún no están presentes en el directorio especificado\n",
    "- *transform=transform* aplica las transformaciones definidas anteriormente a cada imagen\n",
    "\n",
    "En la tercera línea se carga el conjunto de datos y se proporcionan varias funciones de utilidad, configurando los siguientes parámetros:\n",
    "- *trainset* es el conjunto de datos del cual se cargarán los datos\n",
    "- *batch_size=4* especifica que se devolverán cuatro muestras por lote\n",
    "- *shuffle=True* significa que los datos se barajarán en cada epoch\n",
    "\n",
    "La cuarta línea:\n",
    "- *net = SimpleNet()* inicializa una instancia de SimpleNet, que es el modelo de red neuronal que se ha definido antes\n",
    "\n",
    "Quinta línea:\n",
    "- *criterion = nn.CrossEntropyLoss()* establece la función de pérdida a la Entropía Cruzada, que se utiliza comúnmente para tareas de clasificación\n",
    "\n",
    "Sexta línea, se define el optimizador para entrenar la red neuronal, utilizando el SDG como algoritmo de optimización:\n",
    "- *net.parameters()* proporciona los parámetros del modelo SimpleNet que serán optimizados\n",
    "- *lr=0.001* establece la tasa de aprendizaje, que determina el tamaño del paso en cada iteración mientras se avanza hacia un mínimo de la función de pérdida\n",
    "- *momentum=0.9* es un parámetro que ayuda a acelerar el SGD en la dirección relevante y amortigua las oscilaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eda48a-de30-41d5-93c6-e8793e9e470e",
   "metadata": {},
   "source": [
    "Explicación del bucle:\n",
    "\n",
    "Cada paso completo a través del conjunto de datos se conoce como un epoch. Durante cada epoch, el modelo intenta aprender y ajustar sus parámetros internos (pesos y sesgos) para poder predecir mejor las etiquetas de los datos de entrada.\n",
    "\n",
    "Al inicio de cada epoch, se inicializa running_loss a 0.0.\n",
    "\n",
    "Se itera a través de trainloader, que es un DataLoader de PyTorch. Este DataLoader sirve lotes (batch) de imágenes y etiquetas correspondientes del conjunto de datos MNIST. Cada lote contiene 4 imágenes debido a batch_size=4 especificado al crear trainloader (al principio de la función train()).\n",
    "\n",
    "*optimizer.zero_grad()* se usa para poner a cero los gradientes de todos los parámetros en el modelo. Esto se hace porque, por defecto, los gradientes se acumulan en PyTorch.\n",
    "\n",
    "Predicción y Pérdida: Se pasa un lote de imágenes a través de la red (outputs = net(inputs)) y luego se calcula la pérdida utilizando la función de pérdida de entropía cruzada (loss = criterion(outputs, labels)).\n",
    "\n",
    "Backpropagation: loss.backward() calcula el gradiente de la pérdida con respecto a todos los parámetros del modelo que son diferenciables.\n",
    "\n",
    "Actualización de Parámetros: optimizer.step() actualiza los parámetros del modelo en dirección que reduce la pérdida, utilizando los gradientes calculados y el algoritmo de optimización (en este caso, SGD con momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a32f30a-874f-4f94-a11e-4c4c025ff26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define la función de entrenamiento\n",
    "\n",
    "def train():\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.MNIST(root='/Users/n.c.rodriguez/nico/curso_AI/IA generativa/Pytorch', train=True, download=True, transform=transform)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "\n",
    "    net = SimpleNet()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    for epoch in range(2): # loop sobre el dataset 2 veces\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if i % 2000 == 1999:    # imprime cada 2000 mini-batches \n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000)) \n",
    "                running_loss = 0.0\n",
    "\n",
    "    # Por último se guarda el modelo en un archivo para poder cargarlo más adelante\n",
    "    print('Finished Training')\n",
    "    torch.save(net.state_dict(), 'modelo_mnist.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3277db9d-d947-4920-8fe6-e1be6cc90cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /Users/n.c.rodriguez/nico/curso_AI/IA generativa/Pytorch/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 7314636.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/n.c.rodriguez/nico/curso_AI/IA generativa/Pytorch/MNIST/raw/train-images-idx3-ubyte.gz to /Users/n.c.rodriguez/nico/curso_AI/IA generativa/Pytorch/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /Users/n.c.rodriguez/nico/curso_AI/IA generativa/Pytorch/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 1000319.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/n.c.rodriguez/nico/curso_AI/IA generativa/Pytorch/MNIST/raw/train-labels-idx1-ubyte.gz to /Users/n.c.rodriguez/nico/curso_AI/IA generativa/Pytorch/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /Users/n.c.rodriguez/nico/curso_AI/IA generativa/Pytorch/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 6202437.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/n.c.rodriguez/nico/curso_AI/IA generativa/Pytorch/MNIST/raw/t10k-images-idx3-ubyte.gz to /Users/n.c.rodriguez/nico/curso_AI/IA generativa/Pytorch/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /Users/n.c.rodriguez/nico/curso_AI/IA generativa/Pytorch/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 5714015.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/n.c.rodriguez/nico/curso_AI/IA generativa/Pytorch/MNIST/raw/t10k-labels-idx1-ubyte.gz to /Users/n.c.rodriguez/nico/curso_AI/IA generativa/Pytorch/MNIST/raw\n",
      "\n",
      "[1,  2000] loss: 0.652\n",
      "[1,  4000] loss: 0.376\n",
      "[1,  6000] loss: 0.337\n",
      "[1,  8000] loss: 0.295\n",
      "[1, 10000] loss: 0.264\n",
      "[1, 12000] loss: 0.235\n",
      "[1, 14000] loss: 0.224\n",
      "[2,  2000] loss: 0.180\n",
      "[2,  4000] loss: 0.176\n",
      "[2,  6000] loss: 0.178\n",
      "[2,  8000] loss: 0.168\n",
      "[2, 10000] loss: 0.182\n",
      "[2, 12000] loss: 0.163\n",
      "[2, 14000] loss: 0.153\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Usamos el método __init__ para que cada vez que llamemos a nuestro módulo se cargue la función train por defecto.\n",
    "if __name__ == \"__main__\": \n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d729ee-5e2d-4e5d-8e79-45e2a2de1309",
   "metadata": {},
   "source": [
    "## Uso del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "900d961d-bc02-4762-9e8a-7784fbbf0e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNet(\n",
       "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos a usar torchvision para \"leer\" o predecir los números escritos a mano en el directorio raíz:\n",
    "#/Users/n.c.rodriguez/nico/curso_AI/IA generativa/Pytorch\n",
    "# Carga del modelo\n",
    "model = SimpleNet()\n",
    "model.load_state_dict(torch.load('modelo_mnist.pth'))\n",
    "model.eval()  # Importante para decirle al modelo que ahora está en modo de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b6f0480-0d38-4917-a3f2-3066c191f115",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for root, dirs, files in os.walk('/Users/n.c.rodriguez/nico/curso_AI/IA generativa/Pytorch'):\n",
    "    for file in files:\n",
    "        base, extension = os.path.splitext(file) \n",
    "        if (extension.lower() == '.jpg'):\n",
    "            full_path = os.path.join(root, file) \n",
    "            images.append(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468a98a2-d10e-4846-9cd1-6de6e4b72b05",
   "metadata": {},
   "source": [
    "Esta es la función de predicción, admite una imagen y la pasa a través del modelo para interpretar el \n",
    "número escrito a mano. Primero se aplican las tranformaciones para estadarizar la imagen a predecir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df5f4761-d63a-4825-b440-491870a257f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path):\n",
    "    # Se carga la imagen desde la ruta\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Se extrae el nombre del archivo de la ruta\n",
    "    _, filename = os.path.split(image_path)\n",
    "\n",
    "    # Se definen las transformaciones que se deben aplicar a la imagen para que coincida con el formato MNIST \n",
    "    transformations = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((28, 28)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    # Se aplican las transformaciones a la imagen\n",
    "    img_transformed = transformations(image)\n",
    "    \n",
    "    # Se convierte la imagen para que tenga una dimensión de lote (que PyTorch espera) \n",
    "    img_batch = img_transformed.unsqueeze(0)  # Agrega un batch dimension en la posición 0\n",
    "    \n",
    "    # Hacer la predicción\n",
    "    with torch.no_grad():  # No es necesario seguir el rastro de los gradientes\n",
    "        outputs = model(img_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # El resultado 'predicted' es el índice del dígito que el modelo predice\n",
    "    print(f\"El modelo predice que el dígito del archivo {filename} es: {predicted.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48f0b49f-5d4d-44eb-b7ea-89a31e9f886b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo predice que el dígito del archivo numero8.jpg es: 7\n",
      "El modelo predice que el dígito del archivo numero10.jpg es: 7\n",
      "El modelo predice que el dígito del archivo numero1.jpg es: 7\n",
      "El modelo predice que el dígito del archivo numero2.jpg es: 6\n",
      "El modelo predice que el dígito del archivo numero4.jpg es: 1\n",
      "El modelo predice que el dígito del archivo numero5.jpg es: 7\n"
     ]
    }
   ],
   "source": [
    "# Predicción\n",
    "for image_path in images:\n",
    "    predict(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
